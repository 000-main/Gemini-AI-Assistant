#!pip install -q google-genai gradio  -- Please Install this library/module before runnig this script in jupiter notebook or google colab

import gradio as gr
from google import genai
from google.genai import types
import os

# --- 1. Configuration & Client ---
# Pro-tip: Use Colab Secrets (the key icon on the left) to store your API key
API_KEY = "YOUR_API_KEY_HERE" 
client = genai.Client(api_key=API_KEY)

# --- 2. Core Logic ---
def stream_gemini(message, history):
    """
    Handles the conversation flow.
    'message' is the latest user input.
    'history' is a list of previous messages in the chat.
    """
    
    # Setup tools (Google Search grounding)
    tools = [types.Tool(googleSearch=types.GoogleSearch())]
    
    config = types.GenerateContentConfig(
        temperature=0.7,
        tools=tools,
        max_output_tokens=1000,
    )

    # Initialize the streaming response
    try:
        response_stream = client.models.generate_content_stream(
            model="gemini-2.0-flash", # Or your preferred version
            contents=message,
            config=config
        )
        
        full_response = ""
        for chunk in response_stream:
            if chunk.text:
                full_response += chunk.text
                # 'yield' makes the text appear word-by-word in the UI
                yield full_response
                
    except Exception as e:
        yield f"‚ùå Error: {str(e)}"

# --- 3. UI Construction ---
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ü§ñ Gemini AI Assistant")
    gr.Markdown("This app uses the Gemini 2.0 Flash model with live Google Search grounding.")
    
    chatbot = gr.ChatInterface(
        fn=stream_gemini,
        examples=["What is the current stock price of Google?", "Explain quantum computing in 3 sentences."],
        cache_examples=False,
        type="messages" # Optimized for latest Gradio versions
    )

# --- 4. Launch ---
# share=True creates a public URL (ending in .gradio.live)
demo.launch(share=True, debug=True)
